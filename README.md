# Repo Metrics Engine

**A Python-based toolkit for collecting, analyzing, and comparing GitHub repository activity and contributor metrics**

Repo Metrics Engine is designed to help researchers, engineers, and analysts extract meaningful insights from open-source software projects hosted on GitHub. It combines API access and commit history mining to deliver structured, analyzable data on project activity, contributor behavior, and repository health.


## Overview of Scripts

### `top_projects.py`
Retrieves a list of top-starred repositories in a given programming language using the GitHub API.

- Input: programming language, number of top repositories, personal access token
- Output: printed metadata for each project
- Metadata includes: repository name, stars, forks, watchers, pull request count

### `repo_data.py`
Extracts detailed commit-level data from a GitHub repository using PyDriller and the GitHub API.

- Input: GitHub username and repository name
- Output: a CSV file containing:
  - Commit messages
  - Author and committer information
  - Dates, branch info, merge status
  - Code churn (insertions, deletions)
  - DMM metrics (complexity, interfacing, unit size)
  - Repo-wide metadata (forks, open issues)

### `repo_analysis.py`
Processes a commit dataset generated by `repo_data.py` and generates contributor statistics.

- Input: CSV file generated by `repo_data.py`
- Output: another CSV with:
  - Most active authors and committers
  - Duration of contribution
  - Commit frequency per user
  - Share of total commits per contributor

## Requirements

- Python 3.8+
- Dependencies (install with `pip install -r requirements.txt`):

```
pydriller
PyGithub
requests
pandas
```

## Getting Started

### 1. Clone the repository

```bash
git clone git@github.com:aalassil/Repo_Metrics_Engine.git
cd Repo_Metrics_Engine
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Run scripts

#### Get top repositories for a language:

```bash
python top_projects.py
```

#### Extract commit data from a repository:

```bash
python repo_data.py
```

#### Analyze the exported data:

```bash
python repo_analysis.py
```

## Example Use Cases

- Analyze contribution behavior in open-source projects
- Track project activity trends over time
- Identify most influential contributors
- Collect data for academic research or dashboard visualizations

## Project Structure

```
Repo_Metrics_Engine/
├── data/                    # Output CSVs
├── repo_data.py             # GitHub + PyDriller data extractor
├── repo_analysis.py         # Contributor analytics from exported CSV
├── top_projects.py          # GitHub API query for top repositories
├── requirements.txt         # Dependencies
└── README.md
```

## Best Practices

- Use a `.env` or environment variable to store your GitHub token.
- Avoid hardcoding secrets in your scripts.
- Be aware of GitHub API rate limits (especially with anonymous access).
- If you're scanning a large number of commits, increase Python's recursion limit as done in `repo_data.py`.

## License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

## Acknowledgments

- [PyDriller](https://github.com/ishepard/pydriller)
- [PyGithub](https://pygithub.readthedocs.io/)
- GitHub REST API
